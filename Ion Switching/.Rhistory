#stopping_metric = 'misclassification',
# stopping_tolerance = 0.005
)
accshow(fit_gbm1,test1,T)
fit_gbm1 <- h2o.gbm(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame =  train1, # trn1,  #
validation_frame = test1,
#nfolds = 5,
#fold_assignment = 'Stratified',
#verbose = T,
balance_classes = T,
#class_sampling_factors = c(1,1.25,2.25,1.85,3,4.5,6.6,4.6,5,9,35),
max_depth = 7,
min_rows = 10,
learn_rate = 0.1,
learn_rate_annealing = 0.99,
col_sample_rate = 0.8,
sample_rate = 0.8,
ntrees = 20,
score_tree_interval = 10#,
#stopping_metric = 'misclassification',
# stopping_tolerance = 0.005
)
accshow(fit_gbm1,test1,T)
id=numeric()
for(i in 1:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(15000,length(s)))])
}
id=sort(id)
c(train1,test1) %<-% h2o.splitFrame(data=trn1[id,],ratios = 0.8)
gbm_grid <- h2o.grid(
'gbm',
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame =  train1, # trn1,  #
#validation_frame = test1,
nfolds=5,
hyper_params = list(
balance_classes = T,
max_depth = c(3,4,5,6,7,8,9,10),
min_rows = c(10,20,30,40),
learn_rate = c(0.05,0.1,0.2,0.3),
col_sample_rate = c(0.5,0.65,0.8,1),
sample_rate = c(0.6,0.7,0.8,0.9) ,
ntrees = c(15,20,30,40)
),
search_criteria = list(
strategy = "RandomDiscrete",
max_runtime_secs = 1800,
max_models = 100, seed = 1)
)
gbm_grid
summary(gbm_grid)
fit_gbm1 <- h2o.gbm(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame =  train1, # trn1,  #
validation_frame = test1,
#nfolds = 5,
#fold_assignment = 'Stratified',
#verbose = T,
balance_classes = T,
#class_sampling_factors = c(1,1.25,2.25,1.85,3,4.5,6.6,4.6,5,9,35),
max_depth = 5,
min_rows = 40,
learn_rate = 0.1,
learn_rate_annealing = 1,
col_sample_rate = 0.8,
sample_rate = 0.7,
ntrees = 40,
score_tree_interval = 10#,
#stopping_metric = 'misclassification',
# stopping_tolerance = 0.005
)
accshow(fit_gbm1,test1,T)
fit_rf1 <- h2o.randomForest(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
ntrees = 100,
max_depth = 12,
min_rows = 1,
nbins = 20,
#sample_rate = .6,
col_sample_rate_per_tree = .9#,
#min_split_improvement = .000015
)
accshow(fit_rf1,test1,T)
fit_rf1 <- h2o.randomForest(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
ntrees = 50,
max_depth = 16,
min_rows = 1,
nbins = 20,
sample_rate = .6,
col_sample_rate_per_tree = .9#,
#min_split_improvement = .000015
)
accshow(fit_rf1,test1,T)
fit_rf1 <- h2o.randomForest(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
ntrees = 50,
max_depth = 10,
min_rows = 1,
nbins = 20,
sample_rate = .8,
col_sample_rate_per_tree = .8#,
#min_split_improvement = .000015
)
accshow(fit_rf1,test1,T)
fit_rf1 <- h2o.randomForest(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
ntrees = 50,
max_depth = 7,
min_rows = 1,
nbins = 20,
sample_rate = .8,
col_sample_rate_per_tree = .8#,
#min_split_improvement = .000015
)
accshow(fit_rf1,test1,T)
fit_rf1 <- h2o.randomForest(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
ntrees = 50,
max_depth = 5,
min_rows = 1,
nbins = 20,
sample_rate = .8,
col_sample_rate_per_tree = .8#,
#min_split_improvement = .000015
)
accshow(fit_rf1,test1,T)
fit_rf1 <- h2o.randomForest(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
ntrees = 50,
max_depth = 8,
min_rows = 1,
nbins = 20,
sample_rate = .9,
col_sample_rate_per_tree = .8#,
#min_split_improvement = .000015
)
accshow(fit_rf1,test1,T)
fit_rf1 <- h2o.randomForest(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
ntrees = 70,
max_depth = 8,
min_rows = 1,
nbins = 20,
sample_rate = .9,
col_sample_rate_per_tree = .7#,
#min_split_improvement = .000015
)
accshow(fit_rf1,test1,T)
fit_rf1 <- h2o.randomForest(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
ntrees = 100,
max_depth = 8,
min_rows = 1,
nbins = 20,
sample_rate = .9,
col_sample_rate_per_tree = .7#,
#min_split_improvement = .000015
)
load('result of l1=gbm, l2=gbm.rdata')
accshow(fit_rf1,test1,T)
dl <- h2o.deeplearning(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
distribution = "tweedie",
hidden = c(1),
epochs = 1000,
train_samples_per_iteration = -1,
reproducible = TRUE,
activation = "Tanh",
single_node_mode = FALSE,
balance_classes = FALSE,
force_load_balance = FALSE,
seed = 23123,
tweedie_power = 1.5,
score_training_samples = 0,
score_validation_samples = 0,
training_frame = insurance,
stopping_rounds = 0)
dl <- h2o.deeplearning(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
distribution = "gaussian",
hidden = c(1),
epochs = 1000,
train_samples_per_iteration = -1,
reproducible = TRUE,
activation = "Tanh",
single_node_mode = FALSE,
balance_classes = FALSE,
force_load_balance = FALSE,
seed = 23123,
tweedie_power = 1.5,
score_training_samples = 0,
score_validation_samples = 0,
training_frame = insurance,
stopping_rounds = 0)
dl <- h2o.deeplearning(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
distribution = "gaussian",
hidden = c(1),
epochs = 1000,
train_samples_per_iteration = -1,
reproducible = TRUE,
activation = "Tanh",
single_node_mode = FALSE,
balance_classes = FALSE,
force_load_balance = FALSE,
seed = 23123,
score_training_samples = 0,
score_validation_samples = 0,
stopping_rounds = 0)
dl <- h2o.deeplearning(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
distribution = "gaussian",
hidden = c(1),
epochs = 1000,
train_samples_per_iteration = -1,
reproducible = TRUE,
activation = "Tanh",
single_node_mode = FALSE,
force_load_balance = FALSE,
seed = 23123,
score_training_samples = 0,
score_validation_samples = 0,
stopping_rounds = 0)
dl <- h2o.deeplearning(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
distribution = "multinomial",
hidden = c(1),
epochs = 1000,
train_samples_per_iteration = -1,
reproducible = TRUE,
activation = "Tanh",
single_node_mode = FALSE,
force_load_balance = FALSE,
seed = 23123,
score_training_samples = 0,
score_validation_samples = 0,
stopping_rounds = 0)
dl
accshow(dl,test1,T)
train1
res[levs==1]
load('levs.rdata')
load('levels for test.rdata')
res[levs==1]
res[levs==1] = as.numeric((predict(fit_gbm1, newdata= tst1)$predict %>% as.data.frame.array() %>% tbl_df())$predict)
res[levs==1]
answer=read_csv(paste0(path.dir,'sample_submission.csv'))
answer$time=format(answer$time,nsmall = 4)
answer$open_channels=res
write_csv(answer,paste0(path.dir,'l1=gbm.csv'))
dl <- h2o.deeplearning(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
distribution = "multinomial",
hidden = c(40,40,40),
epochs = 1000,
train_samples_per_iteration = -1,
reproducible = TRUE,
activation = "Tanh",
single_node_mode = FALSE,
force_load_balance = FALSE,
score_training_samples = 0,
score_validation_samples = 0,
stopping_rounds = 0)
dl <- h2o.deeplearning(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
distribution = "multinomial",
hidden = c(40),
epochs = 1000,
train_samples_per_iteration = -1,
reproducible = TRUE,
activation = "Tanh",
single_node_mode = FALSE,
force_load_balance = FALSE,
score_training_samples = 0,
score_validation_samples = 0,
stopping_rounds = 0)
h2o.init(nthreads = 6,
max_mem_size = "9g")
dl <- h2o.deeplearning(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
distribution = "multinomial",
hidden = c(40),
epochs = 1000,
train_samples_per_iteration = -1,
reproducible = TRUE,
activation = "Tanh",
single_node_mode = FALSE,
force_load_balance = FALSE,
score_training_samples = 0,
score_validation_samples = 0,
stopping_rounds = 0)
trn1= trn %>% as.h2o()
tst1=tst %>%  as.h2o()
trn1[,2]=as.factor(trn1[,2]);
id=numeric()
for(i in 1:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(15000,length(s)))])
}
id=sort(id)
c(train1,test1) %<-% h2o.splitFrame(data=trn1[id,],ratios = 0.8)
dl <- h2o.deeplearning(
x = colnames(train1)[-c(2)] ,
y = 'open_channels',
training_frame = train1,  #trn1,
validation_frame = test1,
balance_classes = T,
distribution = "multinomial",
hidden = c(40),
epochs = 1000,
train_samples_per_iteration = -1,
reproducible = TRUE,
activation = "Tanh",
single_node_mode = FALSE,
force_load_balance = FALSE,
score_training_samples = 0,
score_validation_samples = 0,
stopping_rounds = 0)
accshow(dl,test1,T)
library(tidyverse)
library(magrittr)
path.dir='./ignore_data/'
trn=read_csv(paste0(path.dir,'trainsuper.csv'))
tst=read_csv(paste0(path.dir,'testsuper.csv'))
how_many = trn %>% group_by(factor(batches),factor(open_channels)) %>%
summarise(count = n())
trn %<>% mutate(signal2=sign(signal)*sqrt(abs(signal))) %>%
select(-time_batch,-level2,-level_type,-level1,-supersignal)
tst %<>% mutate(signal2=sign(signal)*sqrt(abs(signal)))  %>%
select(-time_batch,-level2,-level_type,-level1,-supersignal)
als=1:nrow(trn)
inds=c(0,0,0,0,0,0,1,1,1,1,0)
id=numeric()
for(btc in 0:9){
if(btc %in% c(4,9)){
k=1
}else{
k=4
}
for(i in 0:10){
s= als[trn$open_channels==i & trn$batches==btc]
if(length(s)>0){
id= c(id,
s[sample(1:length(s),
min(1000*k,length(s)
))])
}
}
}
id=sort(id)
library(h2o)
h2o.init(nthreads = 6,
max_mem_size = "9g")
accshow=function(fit,df,get.matrix=F,plotting=T){
if(plotting){
plot(fit)
h2o.varimp_plot(fit)
}
if(get.matrix){
h2o.performance(fit, df) %>% print()
}
cat('F1 = ',f1_(
( df$open_channels %>% as.data.frame())$open_channels%>% as.numeric(),
(predict(fit, newdata= df)$predict %>% as.data.frame())$predict %>% as.numeric()
) ,'\n')
}
tr=trn %>% select(-batches)%>% as.h2o()
te=tst %>% select(-batches)%>% as.h2o()
tr[,2]=as.factor(tr[,2])
p = h2o.splitFrame(data=tr[id,] ,ratios = 0.8)
train=p[[1]]
test=p[[2]]
fit_gbm <- h2o.gbm(
x = colnames(train)[-c(2)] ,
y = 'open_channels',
training_frame =  train,  #   tr,
validation_frame = test,
#nfolds = 5,
#fold_assignment = 'Stratified',
#verbose = T,
balance_classes = F,
#class_sampling_factors = c(1,1.25,2.25,1.85,3,4.5,6.6,4.6,5,9,35),
max_depth = 10,
min_rows = 20,
learn_rate = 0.2,
learn_rate_annealing = 1,
col_sample_rate = 0.2,
sample_rate = 1.0,
ntrees = 20,
score_tree_interval = 10#,
#stopping_metric = 'misclassification',
# stopping_tolerance = 0.005
)
accshow(fit_gbm,test,T)
f1 <- function (data, lev = NULL,model=NULL) {
cm<-as.matrix(table(actual=data$obs,predicted=data$pred))
diag<-diag(cm)
rowsums<-apply(cm,1,sum)
colsums<-apply(cm,2,sum)
precision <- ifelse(colsums==0,0,diag/colsums)
recall  <- ifelse(rowsums==0,0,diag/rowsums)
f1<- ifelse(precision+recall==0,0,2*precision*recall/(precision+recall))
f1_val <- mean(f1)
names(f1_val) <- c("F1")
return(f1_val)
}
f1_ <- function (obs,pred) {
cm<-as.matrix(table(actual=obs,predicted=pred))
diag<-diag(cm)
rowsums<-apply(cm,1,sum)
colsums<-apply(cm,2,sum)
precision <- ifelse(colsums==0,0,diag/colsums)
recall  <- ifelse(rowsums==0,0,diag/rowsums)
return(mean(ifelse(precision+recall==0,0,2*precision*recall/(precision+recall))))
}
accshow(fit_gbm,test,T)
write_csv(trn,file='train for py.csv')
write_csv(trn,'train for py.csv')
reticulate::repl_python()
import pandas as pd
use_python("C:/ProgramData/Anaconda3/")
quit
library(reticulate)
use_python(python = "C:/ProgramData/Anaconda3/python.exe")
reticulate::repl_python()
import pandas as pd
exit
install.packages(c("labelled", "modelr", "RCurl", "recipes", "usethis", "VGAM"))
reticulate::repl_python()
import pandas as pd
pip install pandas
install
library(tidyverse)
path.dir='./ignore_data/'
rs=read_csv('best py result.csv')
res=rs[[2]]
res
answer=read_csv(paste0(path.dir,'sample_submission.csv'))
answer$time=format(answer$time,nsmall = 4)
answer$open_channels=res
write_csv(answer,paste0(path.dir,'bestpy.csv'))
