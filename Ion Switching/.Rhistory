fit_gbm2 <- h2o.gbm(
x = colnames(train2)[-c(1)] ,
y = 'open_channels',
training_frame =  trn2, #   train2,
validation_frame = test2,
#nfolds = 5,
#fold_assignment = 'Stratified',
#verbose = T,
balance_classes = T,
#class_sampling_factors = c(1,1.25,2.25,1.85,3,4.5,6.6,4.6,5,9,35),
max_depth = 6,
min_rows = 10,
learn_rate = 0.1,
learn_rate_annealing = 0.99,
col_sample_rate = 1,
sample_rate = 0.9,
ntrees = 35,
score_tree_interval = 10#,
#stopping_metric = 'misclassification',
# stopping_tolerance = 0.005
)
fit_gbm2 <- h2o.gbm(
x = colnames(train2)[-c(1)] ,
y = 'open_channels',
training_frame =  trn2, #   train2,
#validation_frame = test2,
#nfolds = 5,
#fold_assignment = 'Stratified',
#verbose = T,
balance_classes = T,
#class_sampling_factors = c(1,1.25,2.25,1.85,3,4.5,6.6,4.6,5,9,35),
max_depth = 6,
min_rows = 10,
learn_rate = 0.1,
learn_rate_annealing = 0.99,
col_sample_rate = 1,
sample_rate = 0.9,
ntrees = 35,
score_tree_interval = 10#,
#stopping_metric = 'misclassification',
# stopping_tolerance = 0.005
)
p = h2o.splitFrame(data=trn1,ratios = 0.8)
train1=p[[1]]
test1=p[[2]]
p = h2o.splitFrame(data=trn2,ratios = 0.8)
train2=p[[1]]
test2=p[[2]]
fit_gbm2 <- h2o.gbm(
x = colnames(train2)[-c(1)] ,
y = 'open_channels',
training_frame =  trn2, #   train2,
validation_frame = test2,
#nfolds = 5,
#fold_assignment = 'Stratified',
#verbose = T,
balance_classes = T,
#class_sampling_factors = c(1,1.25,2.25,1.85,3,4.5,6.6,4.6,5,9,35),
max_depth = 6,
min_rows = 10,
learn_rate = 0.1,
learn_rate_annealing = 0.99,
col_sample_rate = 1,
sample_rate = 0.9,
ntrees = 35,
score_tree_interval = 10#,
#stopping_metric = 'misclassification',
# stopping_tolerance = 0.005
)
accshow(fit_gbm2,test2,T)
tst$level_type==2
res[tst$level_type==2]
res[tst$level_type==2] = (predict(fit_gbm2, newdata= tst2)$predict %>% as.data.frame())$predict# %>% as.numeric() -1
res %>% table()
res[tst$level_type==2]
res[tst$level_type==2] %>% table()
tst1
tst2
trn1
library(tidyverse)
library(magrittr)
path.dir='./ignore_data/'
#trn=read_csv(paste0(path.dir,'train_clean.csv'))
#tst=read_csv(paste0(path.dir,'newtest_pca.csv'))
#tst %<>% mutate(signal2=sign(signal)*sqrt(abs(signal)))
trn=read_csv(paste0(path.dir,'trainsuper.csv'))
tst=read_csv(paste0(path.dir,'testsuper.csv'))
trn %<>% mutate(signal2=sign(supersignal)*sqrt(abs(supersignal)))
tst %<>% mutate(signal2=sign(supersignal)*sqrt(abs(supersignal)))
als=1:nrow(trn)
id=1:nrow(trn)
trn=trn[id,-c(1,3,4)]
tst=tst[,-c(1:3)]
trn1= trn %>% filter(level_type==1) %>% select(-level_type,-level1,-level2) %>% as.h2o()
trn2= trn %>% filter(level_type==2) %>% select(-level_type,-level1,-level2) %>% as.h2o()
tst1=tst %>%  filter(level_type==1) %>% select(-level_type,-level1,-level2) %>% as.h2o()
tst2=tst %>%  filter(level_type==2) %>% select(-level_type,-level1,-level2) %>% as.h2o()
trn1[,1]=as.factor(trn1[,1]); trn2[,1]=as.factor(trn2[,1]);
fit_gbm2 <- h2o.gbm(
x = colnames(train2)[-c(1)] ,
y = 'open_channels',
training_frame =   trn2, #train2,
validation_frame = test2,
#nfolds = 5,
#fold_assignment = 'Stratified',
#verbose = T,
balance_classes = T,
#class_sampling_factors = c(1,1.25,2.25,1.85,3,4.5,6.6,4.6,5,9,35),
max_depth = 6,
min_rows = 10,
learn_rate = 0.1,
learn_rate_annealing = 0.99,
col_sample_rate = 1,
sample_rate = 0.9,
ntrees = 35,
score_tree_interval = 10#,
#stopping_metric = 'misclassification',
# stopping_tolerance = 0.005
)
res[tst$level_type==2] = (predict(fit_gbm2, newdata= tst2)$predict %>% as.data.frame())$predict# %>% as.numeric() -1
res[tst$level_type==2] %>% table()
tst2
trn2
trn2$open_channels
trn2$open_channels %>% table()
h2o.describe(trn2)
res[tst$level_type==2] = (predict(fit_gbm2, newdata= tst2)$predict %>% as.data.frame())$predict -1 # %>% as.numeric() -1
(predict(fit_gbm2, newdata= tst2)$predict %>% as.data.frame())$predict %>% as.numeric() -1
res[tst$level_type==2] = (predict(fit_gbm2, newdata= tst2)$predict %>% as.data.frame())$predict %>% as.numeric() -1
res[tst$level_type==2] %>% table()
res %>% table()
answer=read_csv(paste0(path.dir,'sample_submission.csv'))
answer$time=format(answer$time,nsmall = 4)
answer$open_channels=res
write_csv(answer,paste0(path.dir,'fit_gbm_l2 svmLinear_l1.csv'))
library(tidyverse)
library(magrittr)
path.dir='./ignore_data/'
trn=read_csv(paste0(path.dir,'train_clean.csv'))
trn %<>% mutate(open_channels=factor(open_channels))
test.dir=paste0(path.dir,'newtest_pca.csv')
tst=read_csv(test.dir)
ggplot(tst %>% group_by(batches)%>% slice(sample(1:n(),min(4500,n()))),aes(x=time_batch,y=signal))+geom_point()+
facet_wrap(batches~.)+
#facet_wrap(batches~.,scales = 'free')+
theme_bw()
trn %<>% mutate(level_type=ifelse(batches %in% c(4,9),1,2) %>% factor())
tst %<>% mutate(level_type=ifelse(
(batches==1 &  time_batch<=30) | (batches==0 & (time_batch > 20 & time_batch <= 30))
,1,2) %>% factor())
ggplot(tst %>% group_by(level_type)%>% slice(sample(1:n(),min(4000,n()))),aes(x=time_batch,y=signal))+geom_point()+
facet_wrap(level_type~.)+
#facet_wrap(batches~.,scales = 'free')+
theme_bw()
# нужно узнать, какие более репрезентативные в плане медианы (по количеству)
trn %>% group_by(level_type, open_channels) %>% summarise(count = n())
l1_5=trn %>% filter(open_channels==5 & level_type==1) %>% select(signal) %$% signal
l2_5=trn %>% filter(open_channels==5& level_type==2) %>% select(signal) %$% signal
t.test(l1_5)
t.test(l2_5)
m1=mean(l1_5)
m2=mean(l2_5)
q1=IQR(l1_5)
q2=IQR(l2_5)
trn %<>% mutate(supersignal=ifelse(level_type==2,(signal-(m2-m1)), signal))
tst %<>% mutate(supersignal=ifelse(level_type==2,(signal-(m2-m1)), signal))
ggplot(trn %>% group_by(open_channels,level_type) %>% slice(sample(1:n(),min(1000,n()))),
aes(x=time_batch,y=supersignal,col=open_channels))+geom_point()+
facet_wrap(level_type~.)+
#facet_wrap(batches~.,scales = 'free')+
theme_bw()
ggplot(tst %>% group_by(level_type)%>% slice(sample(1:n(),min(5000,n()))),
aes(x=time_batch,y=supersignal))+geom_point()+
facet_wrap(level_type~.)+
#facet_wrap(batches~.,scales = 'free')+
theme_bw()
write_csv(trn,paste0(path.dir,'trainsuper.csv'))
write_csv(tst,paste0(path.dir,'testsuper.csv'))
library(tidyverse)
library(magrittr)
path.dir='./ignore_data/'
test.dir=paste0(path.dir,'test_clean_.csv')
train.dir=paste0(path.dir,'train_clean_.csv')
train=read_csv(train.dir)
test=read_csv(test.dir)
train %<>% mutate(open_channels=factor(open_channels))
train$batches<- as.factor((train$time - 0.0001)%/%50)
train$time_batch <- ((train$time - 0.0001)%%50)+0.0001
test$batches<- factor((test$time - 0.0001)%/%10-50)
test$time_batch <- ((test$time - 0.0001)%%10)+0.0001
predict(loess(train$signal[1:10]~train$time_batch[1:20],span = 0.05))
predict(loess(train$signal[2:10]~train$time_batch[1:20],span = 0.05))
predict(loess(train$signal[1:20]~train$time_batch[1:20],span = 0.05))
warnings()
train %<>%
group_by(batches) %>%
mutate(
mean=mean(signal),
iqr=IQR(signal),
diff1=signal-c(0,signal[1:(length(signal)-1)]),
diff4=signal-c(0,0,0,0,signal[1:(length(signal)-4)]),
l005=predict(loess(signal~time_batch,span = 0.05))#,
#l010=predict(loess(signal~time_batch,span = 0.1))
)
ggplot(train %>% filter(batches==3) %>%
seq(1,n(),by=2000) %>% slice(),
aes(x=time_batch,y=signal))+
geom_point(aes(col=open_channels))+
theme_bw()
ggplot(train %>% filter(batches==3) %>%
(seq(1,n(),by=2000) %>% slice()),
aes(x=time_batch,y=signal))+
geom_point(aes(col=open_channels))+
theme_bw()
ggplot(train %>% filter(batches==3) %>%
%>% slice(seq(1,n(),by=2000)),
aes(x=time_batch,y=signal))+
geom_point(aes(col=open_channels))+
theme_bw()
ggplot(train %>% filter(batches==3) %>%
slice(seq(1,n(),by=2000)),
aes(x=time_batch,y=signal))+
geom_point(aes(col=open_channels))+
theme_bw()
ggplot(train %>% filter(batches==3) %>%
slice(seq(1,n(),by=500)),
aes(x=time_batch,y=signal))+
geom_line()+
geom_point(aes(col=open_channels))+
theme_bw()
ggplot(train %>% filter(batches==3) %>%
slice(seq(1,n(),by=800)),
aes(x=time_batch,y=signal))+
geom_line(fill='grey')+
geom_point(aes(col=open_channels))+
theme_bw()
ggplot(train %>% filter(batches==3) %>%
slice(seq(1,n(),by=800)),
aes(x=time_batch,y=signal))+
geom_line(col='grey')+
geom_point(aes(col=open_channels))+
theme_bw()
ggplot(train %>% filter(batches==3) %>%
slice(seq(1,n(),by=1000)),
aes(x=time_batch,y=signal))+
geom_line(col='grey')+
geom_point(aes(col=open_channels))+
geom_line(aes(y=l005))+
theme_bw()
ggplot(train %>% filter(batches==3) %>%
slice(seq(1,n(),by=1000)),
aes(x=time_batch,y=signal))+
geom_line(col='grey')+
geom_point(aes(col=open_channels))+
geom_line(aes(y=l005))+
geom_line(aes(x=diff1))+
theme_bw()
ggplot(train %>% filter(batches==3) %>%
slice(seq(1,n(),by=1000)),
aes(x=time_batch,y=signal))+
geom_line(col='grey')+
geom_point(aes(col=open_channels))+
geom_line(aes(y=l005))+
geom_line(aes(x=diff4))+
theme_bw()
summary(train)
train %<>% select(-diff1,-diff4)
train %<>%
group_by(batches) %>%
summarise(
mean=mean(signal),
iqr=IQR(signal)
)
library(tidyverse)
library(magrittr)
path.dir='./ignore_data/'
test.dir=paste0(path.dir,'test_clean_.csv')
train.dir=paste0(path.dir,'train_clean_.csv')
train=read_csv(train.dir)
test=read_csv(test.dir)
train %<>% mutate(open_channels=factor(open_channels))
train$batches<- as.factor((train$time - 0.0001)%/%50)
train$time_batch <- ((train$time - 0.0001)%%50)+0.0001
test$batches<- factor((test$time - 0.0001)%/%10-50)
test$time_batch <- ((test$time - 0.0001)%%10)+0.0001
train %<>%
group_by(batches) %>%
mutate(
mean=mean(signal),
iqr=IQR(signal),
l005=predict(loess(signal~time_batch,span = 0.05))
)
train %>%
group_by(batches) %>%
summarise(
mean=mean(signal),
iqr=IQR(signal)
)
roll=function(vector,f,window=100){
len=length(vector)
result=numeric(length = len)
for(i in 1:(len-window+1)){
result[i]=f(vector[i:(i+window)])
}
result[(len-window+2):len]=result[len-window+1]
return(result)
}
roll(1:10,mean,2)
roll=function(vector,f,window=100){
len=length(vector)
result=numeric(length = len)
for(i in 1:(len-window)){
result[i]=f(vector[i:(i+window-1)])
}
result[(len-window+1):len]=result[len-window]
return(result)
}
roll(1:10,mean,2)
library(compiler)
roll=function(vector,f,window=100){
len=length(vector)
result=numeric(length = len)
for(i in 1:(len-window)){
result[i]=f(vector[i:(i+window-1)])
}
result[(len-window+1):len]=result[len-window]
return(result)
}
rollmean_=function(vector,window=100){
len=length(vector)
result=numeric(length = len)
for(i in 1:(len-window)){
result[i]=mean(vector[i:(i+window-1)])
}
result[(len-window+1):len]=result[len-window]
return(result)
}
rollIQR_=function(vector,window=100){
len=length(vector)
result=numeric(length = len)
for(i in 1:(len-window)){
result[i]=IQR(vector[i:(i+window-1)])
}
result[(len-window+1):len]=result[len-window]
return(result)
}
rollmin_=function(vector,window=100){
len=length(vector)
result=numeric(length = len)
for(i in 1:(len-window)){
result[i]=min(vector[i:(i+window-1)])
}
result[(len-window+1):len]=result[len-window]
return(result)
}
rollmax_=function(vector,window=100){
len=length(vector)
result=numeric(length = len)
for(i in 1:(len-window)){
result[i]=max(vector[i:(i+window-1)])
}
result[(len-window+1):len]=result[len-window]
return(result)
}
rollmean=cmpfun(rollmean_)
rollIQR=cmpfun(rollIQR_)
rollmin=cmpfun(rollmin_)
rollmax=cmpfun(rollmax_)
train %<>%
group_by(batches) %>%
mutate(
mean50=rollmean(signal,50),
mean100=rollmean(signal,100),
iqr100=rollIQR(signal,100),
min50=rollmin(50),
max50=rollmax(50),
range50=max50-min50
)
roll=function(vector,f,window=100){
len=length(vector)
result=numeric(length = len)
for(i in 1:(len-window+1)){
result[i]=f(vector[i:(i+window-1)])
}
result[(len-window+2):len]=result[len-window+1]
return(result)
}
roll(1:30,mean,3)
roll(1:30,mean,4)
library(compiler)
roll=function(vector,f,window=100){
len=length(vector)
result=numeric(length = len)
for(i in 1:(len-window+1)){
result[i]=f(vector[i:(i+window-1)])
}
result[(len-window+2):len]=result[len-window+1]
return(result)
}
rollmean_=function(vector,window=100){
len=length(vector)
result=numeric(length = len)
for(i in 1:(len-window+1)){
result[i]=mean(vector[i:(i+window-1)])
}
result[(len-window+2):len]=result[len-window+1]
return(result)
}
rollIQR_=function(vector,window=100){
len=length(vector)
result=numeric(length = len)
for(i in 1:(len-window+1)){
result[i]=IQR(vector[i:(i+window-1)])
}
result[(len-window+2):len]=result[len-window+1]
return(result)
}
rollmin_=function(vector,window=100){
len=length(vector)
result=numeric(length = len)
for(i in 1:(len-window+1)){
result[i]=min(vector[i:(i+window-1)])
}
result[(len-window+2):len]=result[len-window+1]
return(result)
}
rollmax_=function(vector,window=100){
len=length(vector)
result=numeric(length = len)
for(i in 1:(len-window+1)){
result[i]=max(vector[i:(i+window-1)])
}
result[(len-window+2):len]=result[len-window+1]
return(result)
}
rollmean=cmpfun(rollmean_)
rollIQR=cmpfun(rollIQR_)
rollmin=cmpfun(rollmin_)
rollmax=cmpfun(rollmax_)
train %<>%
group_by(batches) %>%
mutate(
mean50=rollmean(signal,50),
mean100=rollmean(signal,100),
iqr100=rollIQR(signal,100),
min50=rollmin(50),
max50=rollmax(50),
range50=max50-min50
)
train %<>%
group_by(batches) %>%
mutate(
mean50=rollmean(signal,50),
mean100=rollmean(signal,100),
iqr100=rollIQR(signal,100),
min50=rollmin(signal,50),
max50=rollmax(signal,50),
range50=max50-min50
)
summary(train)
train %>%
group_by(batches) %>%
summarise(
mean=mean(signal),
iqr=IQR(signal)
)
test %<>%
group_by(batches) %>%
mutate(
mean=mean(signal),
iqr=IQR(signal),
l005=predict(loess(signal~time_batch,span = 0.05)),
mean50=rollmean(signal,50),
mean100=rollmean(signal,100),
iqr100=rollIQR(signal,100),
min50=rollmin(signal,50),
max50=rollmax(signal,50),
range50=max50-min50
)
test %>%
group_by(batches) %>%
summarise(
mean=mean(signal),
iqr=IQR(signal)
)
write_csv(train,path=paste0(path.dir,'train_last.csv'))
write_csv(test,path=paste0(path.dir,'test_last.csv'))
train %<>% mutate(level=ifelse(iqr>2,1,0))
test %<>% mutate(level=ifelse(iqr>2,1,0))
write_csv(train,path=paste0(path.dir,'train_last.csv'))
write_csv(test,path=paste0(path.dir,'test_last.csv'))
trn=train
trn %<>% mutate(outliers=F)
als=1:nrow(trn)
for(lv in 0:1){
for(ch in 0:10){
id = als[trn$open_channels == ch & trn$level == lv]
if(length(id)==0){
next
}
ind <- which(trn$signal[id] %in% boxplot.stats(trn$signal[id])$out)
if(length(ind)==0){
next
}
trn$outliers[id[ind]]=T
cat('level = ',lv,' chan = ',ch,' len = ',length(ind),'\n')
}
}
sum(trn$outliers)/nrow(trn)
trn %>% group_by(open_channels) %>% summarise(count=sum(outliers))
sum(trn$outliers)
write_csv(trn %>% filter(outliers==F) %>% select(-outliers),path=paste0(path.dir,'train_last_clean.csv'))
