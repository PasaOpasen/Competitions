path.dir='./ignore_data/'
#trn=read_csv(paste0(path.dir,'train_clean.csv'))
#tst=read_csv(paste0(path.dir,'newtest_pca.csv'))
#tst %<>% mutate(signal2=sign(signal)*sqrt(abs(signal)))
trn=read_csv(paste0(path.dir,'trainsuper.csv'))
tst=read_csv(paste0(path.dir,'testsuper.csv'))
als=1:nrow(trn)
#trn %>% group_by(factor(open_channels)) %>% summarise(count=n())
# test inds
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(60000,length(s)))]) #+50*i
}
library(h2o)
h2o.init(nthreads = 6,
max_mem_size = "9g")
accshow=function(fit,df,get.matrix=F){
plot(fit)
h2o.varimp_plot(fit)
if(get.matrix){
h2o.performance(fit, df) %>% print()
}
cat('F1 = ',f1_(
( df$open_channels %>% as.data.frame())$open_channels%>% as.numeric(),
(predict(fit, newdata= df)$predict %>% as.data.frame())$predict %>% as.numeric()
) ,'\n')
}
trn=trn[id,-c(3,4)] %>% as.h2o()
tst=tst[,c(1,4:13)] %>% as.h2o()
trn[,2]=as.factor(trn[,2])
#set.seed(1998)
p = h2o.splitFrame(data=trn,ratios = 0.9,seed=1)
train=p[[1]]
test=p[[2]]
fit_gbm <- h2o.gbm(
x = colnames(train)[-c(2)] ,
y = 'open_channels',
training_frame =  train, # trn,
validation_frame = test,
#nfolds = 5,
#fold_assignment = 'Stratified',
#verbose = T,
balance_classes = T,
#class_sampling_factors = c(1,1.25,2.25,1.85,3,4.5,6.6,4.6,5,9,35),
max_depth = 6,
min_rows = 10,
learn_rate = 0.1,
learn_rate_annealing = 1,
col_sample_rate = 0.8,
sample_rate = 0.9,
ntrees = 70,
score_tree_interval = 10#,
#stopping_metric = 'misclassification',
# stopping_tolerance = 0.005
)
accshow(fit_gbm,test,F)
f1_ <- function (obs,pred) {
cm<-as.matrix(table(actual=obs,predicted=pred))
diag<-diag(cm)
rowsums<-apply(cm,1,sum)
colsums<-apply(cm,2,sum)
precision <- ifelse(colsums==0,0,diag/colsums)
recall  <- ifelse(rowsums==0,0,diag/rowsums)
return(mean(ifelse(precision+recall==0,0,2*precision*recall/(precision+recall))))
}
accshow(fit_gbm,test,F)
h2o.shutdown(prompt = FALSE)
library(tidyverse)
library(magrittr)
path.dir='./ignore_data/'
#trn=read_csv(paste0(path.dir,'train_clean.csv'))
#tst=read_csv(paste0(path.dir,'newtest_pca.csv'))
#tst %<>% mutate(signal2=sign(signal)*sqrt(abs(signal)))
trn=read_csv(paste0(path.dir,'trainsuper.csv'))
tst=read_csv(paste0(path.dir,'testsuper.csv'))
als=1:nrow(trn)
#trn %>% group_by(factor(open_channels)) %>% summarise(count=n())
# test inds
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(60000,length(s)))]) #+50*i
}
colnames(trn)
colnames(tst)
trn %<>% mutate(signal2=sign(supersignal)*sqrt(abs(supersignal)))
tst %<>% mutate(signal2=sign(supersignal)*sqrt(abs(supersignal)))
colnames(trn)
library(h2o)
h2o.init(nthreads = 6,
max_mem_size = "9g")
accshow=function(fit,df,get.matrix=F){
plot(fit)
h2o.varimp_plot(fit)
if(get.matrix){
h2o.performance(fit, df) %>% print()
}
cat('F1 = ',f1_(
( df$open_channels %>% as.data.frame())$open_channels%>% as.numeric(),
(predict(fit, newdata= df)$predict %>% as.data.frame())$predict %>% as.numeric()
) ,'\n')
}
colnames(trn)
trn=trn[id,-c(1,3,4)] %>% as.h2o()
tst=tst[,4:13] %>% as.h2o()
colnames(trn)
colnames(tst)
trn[,2]=as.factor(trn[,2])
trn[,10]=as.factor(trn[,10])
tst[,8]=as.factor(tst[,8])
library(tidyverse)
library(magrittr)
path.dir='./ignore_data/'
#trn=read_csv(paste0(path.dir,'train_clean.csv'))
#tst=read_csv(paste0(path.dir,'newtest_pca.csv'))
#tst %<>% mutate(signal2=sign(signal)*sqrt(abs(signal)))
trn=read_csv(paste0(path.dir,'trainsuper.csv'))
tst=read_csv(paste0(path.dir,'testsuper.csv'))
trn %<>% mutate(signal2=sign(supersignal)*sqrt(abs(supersignal)))
tst %<>% mutate(signal2=sign(supersignal)*sqrt(abs(supersignal)))
als=1:nrow(trn)
#trn %>% group_by(factor(open_channels)) %>% summarise(count=n())
# test inds
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(60000,length(s)))]) #+50*i
}
library(h2o)
h2o.init(nthreads = 6,
max_mem_size = "9g")
accshow=function(fit,df,get.matrix=F){
plot(fit)
h2o.varimp_plot(fit)
if(get.matrix){
h2o.performance(fit, df) %>% print()
}
cat('F1 = ',f1_(
( df$open_channels %>% as.data.frame())$open_channels%>% as.numeric(),
(predict(fit, newdata= df)$predict %>% as.data.frame())$predict %>% as.numeric()
) ,'\n')
}
trn=trn[id,-c(1,3,4)] %>% as.h2o()
tst=tst[,4:13] %>% as.h2o()
trn[,1]
trn[,1]=as.factor(trn[,1])
trn[,10]
trn[,10]=as.factor(trn[,10])
tst[,8]
tst[,8]=as.factor(tst[,8])
p = h2o.splitFrame(data=trn,ratios = 0.9,seed=1)
train=p[[1]]
test=p[[2]]
train
fit_gbm <- h2o.gbm(
x = colnames(train)[-c(1)] ,
y = 'open_channels',
training_frame =  train, # trn,
validation_frame = test,
#nfolds = 5,
#fold_assignment = 'Stratified',
#verbose = T,
balance_classes = T,
#class_sampling_factors = c(1,1.25,2.25,1.85,3,4.5,6.6,4.6,5,9,35),
max_depth = 6,
min_rows = 10,
learn_rate = 0.1,
learn_rate_annealing = 1,
col_sample_rate = 0.8,
sample_rate = 0.9,
ntrees = 70,
score_tree_interval = 10#,
#stopping_metric = 'misclassification',
# stopping_tolerance = 0.005
)
accshow(fit_gbm,test,F)
f1_ <- function (obs,pred) {
cm<-as.matrix(table(actual=obs,predicted=pred))
diag<-diag(cm)
rowsums<-apply(cm,1,sum)
colsums<-apply(cm,2,sum)
precision <- ifelse(colsums==0,0,diag/colsums)
recall  <- ifelse(rowsums==0,0,diag/rowsums)
return(mean(ifelse(precision+recall==0,0,2*precision*recall/(precision+recall))))
}
accshow(fit_gbm,test,F)
accshow(fit_gbm,test,T)
fit_gbm <- h2o.gbm(
x = colnames(train)[-c(1)] ,
y = 'open_channels',
training_frame =  train, # trn,
validation_frame = test,
#nfolds = 5,
#fold_assignment = 'Stratified',
#verbose = T,
balance_classes = T,
#class_sampling_factors = c(1,1.25,2.25,1.85,3,4.5,6.6,4.6,5,9,35),
max_depth = 7,
min_rows = 10,
learn_rate = 0.1,
learn_rate_annealing = 1,
col_sample_rate = 0.8,
sample_rate = 0.9,
ntrees = 70,
score_tree_interval = 10#,
#stopping_metric = 'misclassification',
# stopping_tolerance = 0.005
)
accshow(fit_gbm,test,F)
fit_gbm <- h2o.gbm(
x = colnames(train)[-c(1)] ,
y = 'open_channels',
training_frame =  train, # trn,
validation_frame = test,
#nfolds = 5,
#fold_assignment = 'Stratified',
#verbose = T,
balance_classes = T,
#class_sampling_factors = c(1,1.25,2.25,1.85,3,4.5,6.6,4.6,5,9,35),
max_depth = 11,
min_rows = 10,
learn_rate = 0.1,
learn_rate_annealing = 1,
col_sample_rate = 0.8,
sample_rate = 0.9,
ntrees = 70,
score_tree_interval = 10#,
#stopping_metric = 'misclassification',
# stopping_tolerance = 0.005
)
accshow(fit_gbm,test,F)
fit_gbm <- h2o.gbm(
x = colnames(train)[-c(1)] ,
y = 'open_channels',
training_frame =  train, # trn,
validation_frame = test,
#nfolds = 5,
#fold_assignment = 'Stratified',
#verbose = T,
balance_classes = T,
#class_sampling_factors = c(1,1.25,2.25,1.85,3,4.5,6.6,4.6,5,9,35),
max_depth = 6,
min_rows = 10,
learn_rate = 0.1,
learn_rate_annealing = 1,
col_sample_rate = 0.9,
sample_rate = 0.9,
ntrees = 70,
score_tree_interval = 10#,
#stopping_metric = 'misclassification',
# stopping_tolerance = 0.005
)
accshow(fit_gbm,test,F)
fit_gbm <- h2o.gbm(
x = colnames(train)[-c(1)] ,
y = 'open_channels',
training_frame =  train, # trn,
validation_frame = test,
#nfolds = 5,
#fold_assignment = 'Stratified',
#verbose = T,
balance_classes = T,
#class_sampling_factors = c(1,1.25,2.25,1.85,3,4.5,6.6,4.6,5,9,35),
max_depth = 6,
min_rows = 10,
learn_rate = 0.1,
learn_rate_annealing = 1,
col_sample_rate = 1,
sample_rate = 0.9,
ntrees = 70,
score_tree_interval = 10#,
#stopping_metric = 'misclassification',
# stopping_tolerance = 0.005
)
accshow(fit_gbm,test,F)
fit_rf <- h2o.randomForest(
x = colnames(train)[-c(1)] ,
y = 'open_channels',
training_frame =  train, # trn,
validation_frame = test,
balance_classes = T,
ntrees = 130,
max_depth = 18,
min_rows = 1,
nbins = 20,
sample_rate = .6,
col_sample_rate_per_tree = .7,
min_split_improvement = .000015
)
accshow(fit_rf,test,F)
fit_gbm <- h2o.gbm(
x = colnames(train)[-c(1)] ,
y = 'open_channels',
training_frame =   trn,#    train,
validation_frame = test,
#nfolds = 5,
#fold_assignment = 'Stratified',
#verbose = T,
balance_classes = T,
#class_sampling_factors = c(1,1.25,2.25,1.85,3,4.5,6.6,4.6,5,9,35),
max_depth = 6,
min_rows = 10,
learn_rate = 0.1,
learn_rate_annealing = 1,
col_sample_rate = 1,
sample_rate = 0.9,
ntrees = 70,
score_tree_interval = 10#,
#stopping_metric = 'misclassification',
# stopping_tolerance = 0.005
)
res = (predict(fit_gbm, newdata= tst)$predict %>% as.data.frame())$predict# %>% as.numeric() -1
answer=read_csv(paste0(path.dir,'sample_submission.csv'))
answer$time=format(answer$time,nsmall = 4)
answer$open_channels=res
write_csv(answer,paste0(path.dir,'fit_gbm super 60000.csv'))
accshow(fit_gbm,test,F)
library(tidyverse)
library(magrittr)
path.dir='./ignore_data/'
#trn=read_csv(paste0(path.dir,'train_clean.csv'))
#tst=read_csv(paste0(path.dir,'newtest_pca.csv'))
#tst %<>% mutate(signal2=sign(signal)*sqrt(abs(signal)))
trn=read_csv(paste0(path.dir,'trainsuper.csv'))
tst=read_csv(paste0(path.dir,'testsuper.csv'))
trn %<>% mutate(signal2=sign(supersignal)*sqrt(abs(supersignal)))
tst %<>% mutate(signal2=sign(supersignal)*sqrt(abs(supersignal)))
als=1:nrow(trn)
trn=trn[,-c(1,3,4)] %>% as.h2o()
tst=tst[,4:13] %>% as.h2o()
trn[,1]=as.factor(trn[,1])
trn[,10]=as.factor(trn[,10])
tst[,8]=as.factor(tst[,8])
fit_gbm <- h2o.gbm(
x = colnames(train)[-c(1)] ,
y = 'open_channels',
training_frame =  trn, #  train,
validation_frame = test,
#nfolds = 5,
#fold_assignment = 'Stratified',
#verbose = T,
balance_classes = T,
#class_sampling_factors = c(1,1.25,2.25,1.85,3,4.5,6.6,4.6,5,9,35),
max_depth = 6,
min_rows = 10,
learn_rate = 0.1,
learn_rate_annealing = 1,
col_sample_rate = 1,
sample_rate = 0.9,
ntrees = 70,
score_tree_interval = 10#,
#stopping_metric = 'misclassification',
# stopping_tolerance = 0.005
)
res = (predict(fit_gbm, newdata= tst)$predict %>% as.data.frame())$predict# %>% as.numeric() -1
answer=read_csv(paste0(path.dir,'sample_submission.csv'))
answer$time=format(answer$time,nsmall = 4)
answer$open_channels=res
write_csv(answer,paste0(path.dir,'fit_gbm super all.csv'))
h2o.shutdown(prompt = FALSE)
library(reticulate)
use_virtualenv("/home/ledell/venv/h2o4gpu")
library(tidyverse)
library(magrittr)
path.dir='./ignore_data/'
#trn=read_csv(paste0(path.dir,'train_clean.csv'))
#tst=read_csv(paste0(path.dir,'newtest_pca.csv'))
#tst %<>% mutate(signal2=sign(signal)*sqrt(abs(signal)))
trn=read_csv(paste0(path.dir,'trainsuper.csv'))
tst=read_csv(paste0(path.dir,'testsuper.csv'))
trn %<>% mutate(signal2=sign(supersignal)*sqrt(abs(supersignal)))
tst %<>% mutate(signal2=sign(supersignal)*sqrt(abs(supersignal)))
als=1:nrow(trn)
#trn %>% group_by(factor(open_channels)) %>% summarise(count=n())
# test inds
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(60000,length(s)))]) #+50*i
}
library(h2o4gpu)
library(reticulate)  # only needed if using a virtual Python environment
use_virtualenv("/home/ledell/venv/h2o4gpu")  # set this to the path of your venv
id_train=numeric()
id_test=numeric()
for(i in 0:10){
id= als[trn$open_channels==i]
id=id[sample(1:length(id),3000+50*i)]
id2<-createDataPartition(id,p = 0.3,list = F)[,1]
id_train=c(id_train,id[id2])
id_test=c(id_test, id[-id2])
}
id_train=numeric()
id_test=numeric()
for(i in 0:10){
id= als[trn$open_channels==i]
id=id[sample(1:length(id),3000+50*i)]
id2<-caret::createDataPartition(id,p = 0.3,list = F)[,1]
id_train=c(id_train,id[id2])
id_test=c(id_test, id[-id2])
}
train<-trn[id_train,]
test<-trn[id_test,]
train
id_train=numeric()
id_test=numeric()
for(i in 0:10){
id= als[trn$open_channels==i]
id=id[sample(1:length(id),3000+50*i)]
id2<-caret::createDataPartition(id,p = 0.8,list = F)[,1]
id_train=c(id_train,id[id2])
id_test=c(id_test, id[-id2])
}
train<-trn[id_train,]
test<-trn[id_test,]
library(tidyverse)
library(magrittr)
path.dir='./ignore_data/'
#trn=read_csv(paste0(path.dir,'train_clean.csv'))
#tst=read_csv(paste0(path.dir,'newtest_pca.csv'))
#tst %<>% mutate(signal2=sign(signal)*sqrt(abs(signal)))
trn=read_csv(paste0(path.dir,'trainsuper.csv'))
tst=read_csv(paste0(path.dir,'testsuper.csv'))
trn %<>% mutate(signal2=sign(supersignal)*sqrt(abs(supersignal))) %>%
select(-signal) %>% mutate(level_type=factor(level_type))
tst %<>% mutate(signal2=sign(supersignal)*sqrt(abs(supersignal))) %>%
select(-signal)%>% mutate(level_type=factor(level_type,levels=levels(trn$level_type)))
als=1:nrow(trn)
id_train=numeric()
id_test=numeric()
for(i in 0:10){
id= als[trn$open_channels==i]
id=id[sample(1:length(id),3000+50*i)]
id2<-caret::createDataPartition(id,p = 0.8,list = F)[,1]
id_train=c(id_train,id[id2])
id_test=c(id_test, id[-id2])
}
train<-trn[id_train,]
test<-trn[id_test,]
trn
-1:3
library(tidyverse)
library(magrittr)
path.dir='./ignore_data/'
#trn=read_csv(paste0(path.dir,'train_clean.csv'))
#tst=read_csv(paste0(path.dir,'newtest_pca.csv'))
#tst %<>% mutate(signal2=sign(signal)*sqrt(abs(signal)))
trn=read_csv(paste0(path.dir,'trainsuper.csv'))
tst=read_csv(paste0(path.dir,'testsuper.csv'))
trn %<>% mutate(signal2=sign(supersignal)*sqrt(abs(supersignal))) %>%
select(-signal) %>% mutate(level_type=factor(level_type),open_channel=factor(open_channel))
tst %<>% mutate(signal2=sign(supersignal)*sqrt(abs(supersignal))) %>%
select(-signal)%>% mutate(level_type=factor(level_type,levels=levels(trn$level_type)))
als=1:nrow(trn)
trn=read_csv(paste0(path.dir,'trainsuper.csv'))
tst=read_csv(paste0(path.dir,'testsuper.csv'))
trn %<>% mutate(signal2=sign(supersignal)*sqrt(abs(supersignal))) %>%
select(-signal) %>% mutate(level_type=factor(level_type),open_channels=factor(open_channels))
tst %<>% mutate(signal2=sign(supersignal)*sqrt(abs(supersignal))) %>%
select(-signal)%>% mutate(level_type=factor(level_type,levels=levels(trn$level_type)))
id_train=numeric()
id_test=numeric()
for(i in 0:10){
id= als[trn$open_channels==i]
id=id[sample(1:length(id),3000+50*i)]
id2<-caret::createDataPartition(id,p = 0.8,list = F)[,1]
id_train=c(id_train,id[id2])
id_test=c(id_test, id[-id2])
}
train<-trn[id_train,]
test<-trn[id_test,]
xtrain=train[,-c(1:3)]
model_enc <- h2o4gpu.elastic_net_classifier() %>% fit(xtrain, train$open_channels)
x <- iris[1:4]
y <- as.integer(iris$Species) # all columns, including the response, must be numeric
# Initialize and train the classifier
model <- h2o4gpu.random_forest_classifier() %>% fit(x, y)
# Make predictions
pred <- model %>% predict(x)
# Compute classification error using the Metrics package (note this is training error)
library(Metrics)
ce(actual = y, predicted = pred)
library(h2o4gpu)
library(reticulate)  # only needed if using a virtual Python environment
use_virtualenv("/home/ledell/venv/h2o4gpu")  # set this to the path of your venv
# Prepare data
x <- iris[1:4]
y <- as.integer(iris$Species) # all columns, including the response, must be numeric
# Initialize and train the classifier
model <- h2o4gpu.random_forest_classifier() %>% fit(x, y)
# Make predictions
pred <- model %>% predict(x)
# Compute classification error using the Metrics package (note this is training error)
library(Metrics)
ce(actual = y, predicted = pred)
install.packages("h2o4gpu")
install.packages("h2o4gpu")
library(h2o4gpu)
library(reticulate)  # only needed if using a virtual Python environment
use_virtualenv("/home/ledell/venv/h2o4gpu")  # set this to the path of your venv
# Prepare data
x <- iris[1:4]
y <- as.integer(iris$Species) # all columns, including the response, must be numeric
# Initialize and train the classifier
model <- h2o4gpu.random_forest_classifier() %>% fit(x, y)
# Make predictions
pred <- model %>% predict(x)
# Compute classification error using the Metrics package (note this is training error)
library(Metrics)
ce(actual = y, predicted = pred)
install.packages(c("arm", "labelled", "RcppArmadillo", "RCurl"))
