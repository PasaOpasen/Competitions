method='lda2',
#family="binomial",
trControl=cv2,
tuneGrid=expand.grid(dimen=6),
#verbosity=T,
metric="F1")
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),12000)]) #+50*i
}
rf_=train(open_channels~PC1+PC2+PC3+PC4+PC5+PC6+PC7+signal+signal2+
sin(signal)+cos(signal)+
sin(PC1)+cos(PC1)+
sin(2*signal)+cos(2*signal)
,
data=trn[id,],
method='rf',
#family="binomial",
trControl=cv2,
tuneGrid=expand.grid(mtry=2),
#verbosity=T,
metric="F1")
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),12000)]) #+50*i
}
sda_=train(open_channels~PC1+PC2+PC3+PC4+PC5+PC6+PC7+signal+signal2+
sin(signal)+cos(signal)+
sin(PC1)+cos(PC1)+
sin(2*signal)+cos(2*signal)
,
data=trn[id,],
method='sda',
#family="binomial",
trControl=cv2,
tuneGrid=expand.grid(lambda=0.5,diagonal=F),
#verbosity=T,
metric="F1")
res=ensemble.predict(list(lda2_,rf_,sda_),scores-0.924,tst)
answer=read_csv(paste0(path.dir,'sample_submission.csv'))
answer$time=format(answer$time,nsmall = 4)
answer$open_channels=res
write_csv(answer,paste0(path.dir,'lda2 rf sda count = 12000.csv'))
save(lda2_, rf_, sda_,file='lda2 rf sda count = 12000.csv')
install.packages(c("boot", "class", "KernSmooth", "MASS", "nnet", "pkgbuild", "proxy", "RCurl", "rex", "spatial", "xml2"))
# The following two commands remove any previously installed H2O packages for R.
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }
# Next, we download packages that H2O depends on.
pkgs <- c("RCurl","jsonlite")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}
# Now we download, install and initialize the H2O package for R.
install.packages("h2o", type="source", repos="http://h2o-release.s3.amazonaws.com/h2o/rel-zahradnik/1/R")
trn=read_csv(paste0(path.dir,'train_clean.csv'))
trn %<>% mutate(open_channels=factor(open_channels))
library(tidyverse)
library(caret)
library(magrittr)
trn=read_csv(paste0(path.dir,'train_clean.csv'))
trn %<>% mutate(open_channels=factor(open_channels))
path.dir='./ignore_data/'
#test.dir=paste0(path.dir,'newtest.csv')
#train.dir=paste0(path.dir,'newtrain.csv')
test.dir=paste0(path.dir,'newtest_pca.csv')
train.dir=paste0(path.dir,'newtrain_pca.csv')
trn=read_csv(paste0(path.dir,'train_clean.csv'))
trn %<>% mutate(open_channels=factor(open_channels))
trn=data.table::fread(paste0(path.dir,'train_clean.csv')) %>% as.h2o()
library(h2o)
h2o.init(nthreads = 4,
max_mem_size = "9g")
trn=data.table::fread(paste0(path.dir,'train_clean.csv')) %>% as.h2o()
install.packages("bit64")
colnames(trn)
trn=data.table::fread(paste0(path.dir,'train_clean.csv')) %>% as.h2o()
gc()
set.seed(1998)
split <- h2o.runif(trn)
train <- trn [split <= 0.85,]
test <- trn [split > 0.85,]
fit_gbm <- h2o.gbm(
x = c(1,5:12),
y = 2,
training_frame = train,
max_depth = 4,
min_rows = 10,
learn_rate = 0.1,
col_sample_rate = 0.8,
sample_rate = 0.9,
ntrees = 200,
seed = 100)
h2o.varimp_plot(fit_gbm)
h2o.performance(fit_gbm, test)
trn[,2]=factor(trn[,2])
trn[,2]=as.factor(trn[,2])
set.seed(1998)
split <- h2o.runif(trn)
train <- trn [split <= 0.85,]
test <- trn [split > 0.85,]
tst=data.table::fread(paste0(path.dir,'newtest_pca.csv')) %>% as.h2o()
fit_gbm <- h2o.gbm(
x = c(1,5:12),
y = 2,
training_frame = train,
max_depth = 4,
min_rows = 10,
learn_rate = 0.1,
col_sample_rate = 0.8,
sample_rate = 0.9,
ntrees = 200,
seed = 100)
h2o.shutdown(prompt = FALSE)
h2o.shutdown()
trn=read_csv(paste0(path.dir,'train_clean.csv'))
als=1:nrow(trn)
# test inds
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(30000,length(s)))]) #+50*i
}
h2o.shutdown(prompt = TRUE)
library(tidyverse)
library(magrittr)
trn=read_csv(paste0(path.dir,'train_clean.csv'))
als=1:nrow(trn)
# test inds
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(30000,length(s)))]) #+50*i
}
path.dir='./ignore_data/'
trn=read_csv(paste0(path.dir,'train_clean.csv'))
als=1:nrow(trn)
# test inds
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(30000,length(s)))]) #+50*i
}
# test inds
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(40000,length(s)))]) #+50*i
}
library(h2o)
h2o.init(nthreads = 6,
max_mem_size = "9g")
#trn=data.table::fread(paste0(path.dir,'train_clean.csv')) %>% as.h2o()
trn=trn[id,] %>% as.h2o()
tst=data.table::fread(paste0(path.dir,'newtest_pca.csv')) %>% as.h2o()
trn[,2]=as.factor(trn[,2])
set.seed(1998)
split <- h2o.runif(trn)
split
train <- trn [split <= 0.9,]
test <- trn [split > 0.9,]
fit_gbm <- h2o.gbm(
x = c(1,5:12),
y = 2,
training_frame = train,
max_depth = 4,
min_rows = 10,
learn_rate = 0.1,
col_sample_rate = 0.8,
sample_rate = 0.9,
ntrees = 200,
seed = 100)
plot(fit_gbm)
h2o.varimp_plot(fit_gbm)
h2o.performance(fit_gbm, test)
res=h2o.predict(fit_gbm,tst)
h2o.shutdown(prompt = FALSE)
library(tidyverse)
library(magrittr)
path.dir='./ignore_data/'
trn=read_csv(paste0(path.dir,'train_clean.csv'))
als=1:nrow(trn)
# test inds
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(40000,length(s)))]) #+50*i
}
library(h2o)
h2o.init(nthreads = 6,
max_mem_size = "9g")
#trn=data.table::fread(paste0(path.dir,'train_clean.csv')) %>% as.h2o()
trn=trn[id,] %>% as.h2o()
tst=data.table::fread(paste0(path.dir,'newtest_pca.csv')) %>% as.h2o()
trn[,2]=as.factor(trn[,2])
set.seed(1998)
split <- h2o.runif(trn)
train <- trn [split <= 0.9,]
test <- trn [split > 0.9,]
fit_gbm <- h2o.gbm(
x = colnames(train)[c(1,5:12)] ,
y = 'open_channels',
training_frame = train,
max_depth = 4,
min_rows = 10,
learn_rate = 0.1,
col_sample_rate = 0.8,
sample_rate = 0.9,
ntrees = 200,
seed = 100)
plot(fit_gbm)
h2o.varimp_plot(fit_gbm)
perf<-h2o.performance(fit_gbm, test)
perf
h2o.F1(perf)
tst[1:10,]
predict(fit_gbm, newdata= tst[1:10,])
tst=read_csv(paste0(path.dir,'newtest_pca.csv'))
tst %<>% mutate(signal2=sign(signal)*sqrt(abs(signal)))
tst=tst %>% as.h2o()
predict(fit_gbm, newdata= tst[1:5,])
predict(fit_gbm, newdata= tst[1:5,]) %>% as.numeric()
predict(fit_gbm, newdata= tst[1:5,]) %>% as.data.frame()
predict(fit_gbm, newdata= tst[1:5,]) %>% as.data.frame() %>% max.col(ties.method = 'first')
predict(fit_gbm, newdata= tst[1:5,])$predict
predict(fit_gbm, newdata= tst[1:5,])$predict %>% as.data.frame()
predict(fit_gbm, newdata= tst[1:5,])$predict %>% as.numeric()
predict(fit_gbm, newdata= tst[1:5,])$predict %>% as.data.frame() %>% as.numeric()
predict(fit_gbm, newdata= tst[1:5,])$predict %>% as.data.frame()
res = predict(fit_gbm, newdata= tst[1:5,])$predict %>% as.data.frame()
res$predict
res$predict %>% as.numeric()
res = predict(fit_gbm, newdata= tst)$predict %>% as.data.frame()
library(tidyverse)
library(magrittr)
path.dir='./ignore_data/'
trn=read_csv(paste0(path.dir,'train_clean.csv'))
tst=read_csv(paste0(path.dir,'newtest_pca.csv'))
tst %<>% mutate(signal2=sign(signal)*sqrt(abs(signal)))
als=1:nrow(trn)
# test inds
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(60000,length(s)))]) #+50*i
}
library(h2o)
h2o.init(nthreads = 6,
max_mem_size = "9g")
#trn=data.table::fread(paste0(path.dir,'train_clean.csv')) %>% as.h2o()
trn=trn[id,] %>% as.h2o()
tst=tst %>% as.h2o()
trn[,2]=as.factor(trn[,2])
set.seed(1998)
split <- h2o.runif(trn)
train <- trn [split <= 0.9,]
test <- trn [split > 0.9,]
fit_gbm <- h2o.gbm(
x = colnames(train)[c(1,5:12)] ,
y = 'open_channels',
training_frame = train,
max_depth = 4,
min_rows = 10,
learn_rate = 0.1,
col_sample_rate = 0.8,
sample_rate = 0.9,
ntrees = 120,
seed = 100)
plot(fit_gbm)
h2o.varimp_plot(fit_gbm)
perf<-h2o.performance(fit_gbm, test)
perf
#h2o.F1(perf)
gc()
res = predict(fit_gbm, newdata= tst)$predict %>% as.data.frame()
res=res$predict %>% as.numeric()-1
answer=read_csv(paste0(path.dir,'sample_submission.csv'))
answer$time=format(answer$time,nsmall = 4)
answer$open_channels=res
write_csv(answer,paste0(path.dir,'fit_gbm 60000.csv'))
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(80000,length(s)))]) #+50*i
}
# test inds
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(80000,length(s)))]) #+50*i
}
h2o.shutdown(prompt = FALSE)
# test inds
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(80000,length(s)))]) #+50*i
}
library(tidyverse)
library(magrittr)
path.dir='./ignore_data/'
trn=read_csv(paste0(path.dir,'train_clean.csv'))
tst=read_csv(paste0(path.dir,'newtest_pca.csv'))
tst %<>% mutate(signal2=sign(signal)*sqrt(abs(signal)))
als=1:nrow(trn)
# test inds
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(80000,length(s)))]) #+50*i
}
library(h2o)
h2o.init(nthreads = 6,
max_mem_size = "9g")
#trn=data.table::fread(paste0(path.dir,'train_clean.csv')) %>% as.h2o()
trn=trn[id,] %>% as.h2o()
tst=tst %>% as.h2o()
trn[,2]=as.factor(trn[,2])
set.seed(1998)
split <- h2o.runif(trn)
train <- trn [split <= 0.95,]
test <- trn [split > 0.95,]
fit_gbm <- h2o.gbm(
x = colnames(train)[c(1,5:12)] ,
y = 'open_channels',
training_frame = train,
max_depth = 4,
min_rows = 10,
learn_rate = 0.1,
col_sample_rate = 0.8,
sample_rate = 0.9,
ntrees = 140,
seed = 100)
plot(fit_gbm)
h2o.varimp_plot(fit_gbm)
perf<-h2o.performance(fit_gbm, test)
perf
fit_gbm <- h2o.gbm(
x = colnames(train)[c(1,5:12)] ,
y = 'open_channels',
training_frame = trn,#train,
max_depth = 4,
min_rows = 10,
learn_rate = 0.1,
col_sample_rate = 0.8,
sample_rate = 0.9,
ntrees = 140,
seed = 100)
f1_ <- function (obs,pred, lev = NULL,model=NULL) {
cm<-as.matrix(table(actual=obs,predicted=pred))
diag<-diag(cm)
rowsums<-apply(cm,1,sum)
colsums<-apply(cm,2,sum)
precision <- ifelse(colsums==0,0,diag/colsums)
recall  <- ifelse(rowsums==0,0,diag/rowsums)
return(mean(ifelse(precision+recall==0,0,2*precision*recall/(precision+recall))))
}
test %>% as.data.frame()
(predict(fit_gbm, newdata= tst)$predict %>% as.data.frame())$predict %>% as.numeric()-1
test$open_channels
test$open_channelsas.data.frame()%>% as.numeric()
test$open_channels %>% as.data.frame()%>% as.numeric()
test$open_channels %>% as.data.frame()
test$open_channels %>% as.data.frame()%>% as.numeric()
p=test$open_channels
p
p[,1]
p %>% as.data.frame() %>% as.numeric()
p %>% unclass()
p %>% as.numeric()
p[1]
(p %>% as.data.frame())$open_channels
f1_(
( test$open_channels %>% as.data.frame())$open_channels ,
(predict(fit_gbm, newdata= test)$predict %>% as.data.frame())$predict -1
)
f1_(
( test$open_channels %>% as.data.frame())$open_channels%>% as.numeric() -1 ,
(predict(fit_gbm, newdata= test)$predict %>% as.data.frame())$predict %>% as.numeric() -1
)
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(90000,length(s)))]) #+50*i
}
h2o.shutdown(prompt = FALSE)
library(tidyverse)
library(magrittr)
path.dir='./ignore_data/'
trn=read_csv(paste0(path.dir,'train_clean.csv'))
tst=read_csv(paste0(path.dir,'newtest_pca.csv'))
tst %<>% mutate(signal2=sign(signal)*sqrt(abs(signal)))
als=1:nrow(trn)
# test inds
id=numeric()
for(i in 0:10){
s= als[trn$open_channels==i]
id= c(id,s[sample(1:length(s),min(90000,length(s)))]) #+50*i
}
library(h2o)
h2o.init(nthreads = 6,
max_mem_size = "9g")
trn=trn[id,] %>% as.h2o()
tst=tst %>% as.h2o()
trn[,2]=as.factor(trn[,2])
set.seed(1998)
split <- h2o.runif(trn)
train <- trn [split <= 0.95,]
test <- trn [split > 0.95,]
fit_gbm <- h2o.gbm(
x = colnames(train)[c(1,5:12)] ,
y = 'open_channels',
training_frame = train,#trn,
max_depth = 4,
min_rows = 10,
learn_rate = 0.1,
col_sample_rate = 0.8,
sample_rate = 0.9,
ntrees = 140,
seed = 100)
f1_(
( test$open_channels %>% as.data.frame())$open_channels%>% as.numeric() -1 ,
(predict(fit_gbm, newdata= test)$predict %>% as.data.frame())$predict %>% as.numeric() -1
)
f1_ <- function (obs,pred, lev = NULL,model=NULL) {
cm<-as.matrix(table(actual=obs,predicted=pred))
diag<-diag(cm)
rowsums<-apply(cm,1,sum)
colsums<-apply(cm,2,sum)
precision <- ifelse(colsums==0,0,diag/colsums)
recall  <- ifelse(rowsums==0,0,diag/rowsums)
return(mean(ifelse(precision+recall==0,0,2*precision*recall/(precision+recall))))
}
f1_(
( test$open_channels %>% as.data.frame())$open_channels%>% as.numeric() -1 ,
(predict(fit_gbm, newdata= test)$predict %>% as.data.frame())$predict %>% as.numeric() -1
)
fit_gbm <- h2o.gbm(
x = colnames(train)[c(1,5:12)] ,
y = 'open_channels',
training_frame = train,#trn,
max_depth = 5,
min_rows = 10,
learn_rate = 0.1,
col_sample_rate = 0.8,
sample_rate = 0.9,
ntrees = 140,
seed = 100)
f1_(
( test$open_channels %>% as.data.frame())$open_channels%>% as.numeric() -1 ,
(predict(fit_gbm, newdata= test)$predict %>% as.data.frame())$predict %>% as.numeric() -1
)
fit_gbm <- h2o.gbm(
x = colnames(train)[c(1,5:12)] ,
y = 'open_channels',
training_frame = trn,#train,
max_depth = 5,
min_rows = 10,
learn_rate = 0.1,
col_sample_rate = 0.8,
sample_rate = 0.9,
ntrees = 140,
seed = 100)
h2o.varimp_plot(fit_gbm)
gc()
res = predict(fit_gbm, newdata= tst)$predict %>% as.data.frame()
res=res$predict %>% as.numeric()-1
answer=read_csv(paste0(path.dir,'sample_submission.csv'))
answer$time=format(answer$time,nsmall = 4)
answer$open_channels=res
write_csv(answer,paste0(path.dir,'fit_gbm 90000.csv'))
h2o.shutdown(prompt = FALSE)
fit_gbm
fit_gbm <- h2o.gbm(
x = colnames(train)[c(1,5:12)] ,
y = 'open_channels',
training_frame = train,# trn,
validation_frame = test,
verbose = T,
max_depth = 5,
min_rows = 10,
learn_rate = 0.1,
col_sample_rate = 0.8,
sample_rate = 0.9,
ntrees = 140,
seed = 100)
library(h2o)
h2o.init(nthreads = 6,
max_mem_size = "9g")
#trn=data.table::fread(paste0(path.dir,'train_clean.csv')) %>% as.h2o()
trn=trn[id,] %>% as.h2o()
tst=tst %>% as.h2o()
trn[,2]=as.factor(trn[,2])
set.seed(1998)
split <- h2o.runif(trn)
train <- trn [split <= 0.95,]
test <- trn [split > 0.95,]
fit_gbm <- h2o.gbm(
x = colnames(train)[c(1,5:12)] ,
y = 'open_channels',
training_frame = train,# trn,
validation_frame = test,
verbose = T,
max_depth = 5,
min_rows = 10,
learn_rate = 0.1,
col_sample_rate = 0.8,
sample_rate = 0.9,
ntrees = 140,
seed = 100)
